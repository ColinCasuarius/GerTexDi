{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from statistics import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The overall CEFR level of your text is approximately: C2\n",
      "\n",
      "The average length of sentences in your text is 14.464 words. This corresponds to a level of about C2 on the Common European Framework of Reference.\n",
      "\n",
      "\n",
      "The average length of words in your text is 5.533 characters. \tThis corresponds to a level of about C2 on the Common European Framework of Reference. \tThis may seem like a small number, considering that German is well-known for its very long compound words. \tThat's because this program counts all words, including smaller function words. The more grammatically complex a text is, the more of these smaller function words there is likely to be.\tFor this reason, word length is given less weight in calculating the overall complexity score.\n"
     ]
    }
   ],
   "source": [
    "def clean_input_text(t):\n",
    "\n",
    "\twith open(t) as f:\n",
    "\n",
    "\t\tlines = f.readlines()\n",
    "\t\tclean_lines = []\n",
    "\t\tfor line in lines:\n",
    "\t\t\tclean_line = line.replace('...','.').replace('!', '.').replace('?', '.').replace('’', \"'\").replace('‘', \"'\").replace(\"–\", \".\").replace(\":\", \".\").replace(\";\",\".\").replace(\"?!\", \".\").replace(\"!?\",\".\").replace('‘', '').replace('„','').replace(\"“\",\"\").replace('-',' ').replace(',','').replace('\"','').replace('“','').replace('”','').replace('(','').replace(')','').replace('[','').replace(']','')\n",
    "\t\t\tclean_lines.append(clean_line.strip())\n",
    "\n",
    "\t\tTEXT = \".\".join(clean_lines)\n",
    "\t\treturn(TEXT)\n",
    "\n",
    "##################################################################\n",
    "\n",
    "def word_count(text):\n",
    "\n",
    "\tre_pattern = \"[a-zA-ZßäöüÄÖÜ]+\\\\'?[a-zA-ZßäöüÄÖÜ]*'?[a-zA-ZßäöüÄÖÜ]*\" # letters and apostrophes.\n",
    "\tword_list = re.findall(re_pattern, text)\n",
    "\tWORD_COUNT = len(word_list)\n",
    "\n",
    "\treturn WORD_COUNT\n",
    "\n",
    "##################################################################\n",
    "\n",
    "def sent_length(text):\n",
    "\n",
    "\tre_pattern = \"[a-zA-ZßäöüÄÖÜ]+\\\\'?[a-zA-ZßäöüÄÖÜ]*\\\\'?[a-zA-ZßäöüÄÖÜ]*\\\\.?\" # letters, apostrophes and full stops\t\n",
    "\tword_list = re.findall(re_pattern, text)\n",
    "\tcleaned_text = \" \".join(word_list)\n",
    "\n",
    "\tsent_list = cleaned_text.split('.')\n",
    "\n",
    "\tsent_lengths = []\n",
    "\tfor sent in sent_list:\n",
    "\t\tif len(sent) > 1:\n",
    "\n",
    "\t\t\tsent = sent.lstrip()\n",
    "\t\t\tword_list = sent.split(\" \")\n",
    "\t\t\tnum_words = 0\n",
    "\t\t\tfor word in word_list:\n",
    "\t\t\t\tif word != \"\":\n",
    "\t\t\t\t\tnum_words += 1\n",
    "\t\t\tsent_lengths.append(num_words)\n",
    "\n",
    "\ttry:\n",
    "\t\tSENT_LENm = round(mean(sent_lengths), 3)\n",
    "\n",
    "\texcept:\n",
    "\t\tSENT_LENm = sent_lengths[0]\n",
    "        \n",
    "\treturn SENT_LENm\n",
    "\n",
    "##################################################################\n",
    "\n",
    "def word_length(text):\n",
    "\n",
    "\tre_pattern = \"[a-zA-ZßäöüÄÖÜ]+\\\\'?[a-zA-ZßäöüÄÖÜ]*\\\\'?[a-zA-ZßäöüÄÖÜ]*\" # letters and apostrophes\n",
    "\tword_list = re.findall(re_pattern, text)\n",
    "\n",
    "\t# count number of letters in each word and append to list\n",
    "\tword_lengths = []\n",
    "\tfor word in word_list:\n",
    "\n",
    "\t\tnum_chars = 0\n",
    "\t\tfor char in word:\n",
    "\t\t\tif char != \"'\":\n",
    "\t\t\t\tnum_chars += 1\n",
    "\t\tword_lengths.append(num_chars)\n",
    "\n",
    "\tWORD_LENm = round(mean(word_lengths), 3)\n",
    "\n",
    "\treturn round(WORD_LENm, 3)\n",
    "    \n",
    "##################################################################\n",
    "    \n",
    "def get_data():\n",
    "    \n",
    "\tfname = os.path.join('input_text.txt')\n",
    "\tTEXT = clean_input_text(fname)\n",
    "\tWORD_COUNT = word_count(TEXT)\n",
    "\tSENT_LENm = sent_length(TEXT)\n",
    "\tWORD_LENm = word_length(TEXT)\n",
    "\n",
    "\treturn SENT_LENm, WORD_LENm\n",
    "\n",
    "##################################################################\n",
    "\n",
    "def get_cefr(sl, wl):\n",
    "\n",
    "\tsent_lens = [5.8,7.1,8.1,11.4,13.9,14.4]\n",
    "\tword_lens = [4.7,4.8,4.9,5.4,5.6,6.4]\n",
    "\n",
    "\tcefr_levels = ['A1','A2','B1','B2','C1','C2']\n",
    "\n",
    "\tcefr_index = [0,1,2,3,4,5]\n",
    "\t\n",
    "\tsent_number = min(sent_lens, key=lambda x:abs(x-sl)) # finds the sentence length in the list closest to the input\n",
    "\tword_number = min(word_lens, key=lambda x:abs(x-wl)) # finds the word length in the list closest to the input\n",
    "\t\n",
    "\tsent_index = sent_lens.index(sent_number)\n",
    "\tword_index = word_lens.index(word_number)\n",
    "\n",
    "\t# more weighting given to sentence lengths...\n",
    "\tweighted_index = (sent_index * .75) + (word_index * .25)\n",
    "\n",
    "\t# finds index number closest to weighted index (Python's round function is rubbish for rounding .5 floats correctly)\n",
    "\n",
    "\toverall_index = min(cefr_index, key=lambda x:abs(x-weighted_index))\n",
    "\n",
    "\tprint('\\nThe overall CEFR level of your text is approximately:', cefr_levels[overall_index])\n",
    "\n",
    "\tprint('\\nThe average length of sentences in your text is', sl, 'words. This corresponds to a level of about', cefr_levels[sent_index], 'on the Common European Framework of Reference.\\n')\n",
    "\n",
    "\tprint(\"\\nThe average length of words in your text is\", wl, \"characters. \\\n",
    "\tThis corresponds to a level of about\", cefr_levels[sent_index], \"on the Common European Framework of Reference. \\\n",
    "\tThis may seem like a small number, considering that German is well-known for its very long compound words. \\\n",
    "\tThat's because this program counts all words, including smaller function words. The more grammatically complex a text is, the more of these smaller function words there is likely to be.\\\n",
    "\tFor this reason, word length is given less weight in calculating the overall complexity score.\")\n",
    "\n",
    "##################################################################\n",
    "\n",
    "sl, wl = get_data()\n",
    "get_cefr(sl, wl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
